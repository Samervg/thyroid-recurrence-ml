import pandas as pd
import numpy as np
import joblib
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Multiply, Activation
from tensorflow.keras.layers import Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

# ğŸ”¹ Veriyi yÃ¼kle
df = pd.read_csv("thyroid_data.csv")
X = pd.get_dummies(df.drop("Recurred", axis=1), drop_first=True)
y = df["Recurred"]

# ğŸ”¹ Ã–zellik uyumu kontrolÃ¼
feature_names = joblib.load("scaler/feature_names.pkl")
if list(X.columns) != feature_names:
    raise ValueError("SÃ¼tun isimleri feature_names.pkl ile eÅŸleÅŸmiyor.")
# Hedef deÄŸiÅŸkeni 0 ve 1 olacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼r
y = y.replace({"No": 0, "Yes": 1}).astype(np.float32)

# ğŸ”¹ SMOTE uygulama
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
y_resampled = y_resampled.astype(np.float32)

# ğŸ”¹ Ã–lÃ§ekleme
scaler = joblib.load("scaler/scaler.pkl")
X_scaled = scaler.transform(X_resampled)

# ğŸ”¹ Train-test bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled
)

# ğŸ”¸ Basit Attention mekanizmasÄ±
def attention_block(inputs):
    attention_weights = Dense(inputs.shape[1], activation='softmax')(inputs)
    attention_output = Multiply()([inputs, attention_weights])
    return attention_output

# ğŸ”¹ Model mimarisi
input_dim = X_train.shape[1]
inputs = Input(shape=(input_dim,))
x = Dense(128, activation='relu')(inputs)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)

# ğŸ”¸ Attention katmanÄ±
x = attention_block(x)

x = Dense(64, activation='relu')(x)
x = Dropout(0.3)(x)
outputs = Dense(1, activation='sigmoid')(x)

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# ğŸ”¹ EÄŸitim
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=100,
    batch_size=32,
    callbacks=[early_stop],
    verbose=1
)

# ğŸ”¹ KlasÃ¶r yoksa oluÅŸtur
import os
os.makedirs("models", exist_ok=True)

# ğŸ”¹ Modeli kaydet
model.save("models/dnn_model_attention.h5")
print("âœ… Attention'lÄ± DNN modeli baÅŸarÄ±yla kaydedildi: models/dnn_model_attention.h5")
